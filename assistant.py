import sounddevice as sd
from vosk import Model, KaldiRecognizer
import json
import queue
import subprocess
import os
import winsound

# ---------------- PATHS ----------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

VOSK_MODEL_PATH = os.path.join(BASE_DIR, "vosk-model-small-hi-0.22")

PIPER_EXE = os.path.join(BASE_DIR, "piper", "piper.exe")

SONG_PATH = os.path.join(BASE_DIR, "music", "Chammak Challo Ra One.wav")

# ---------------- AUDIO CONFIG ----------------
SAMPLE_RATE = 16000
q = queue.Queue()

# ---------------- STATE ----------------
awake = False
last_text = ""
music_playing = False

# üîπ Male / Female voices
current_voice = "male"
VOICE_MODELS = {
    "male": os.path.join(BASE_DIR, "piper", "model", "hi_IN-rohan-medium.onnx"),
    "female": os.path.join(BASE_DIR, "piper", "model", "hi_IN-priyamvada-medium.onnx"),
}

WAKE_WORDS = ["‡§∏‡•Å‡§®‡•ã", "‡§π‡•á‡§≤‡•ã", "‡§Ö‡§∞‡•á"]
SLEEP_WORDS = ["‡§¨‡§Ç‡§¶", "‡§ö‡•Å‡§™"]
TERMINATE_WORDS = ["‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§¨‡§Ç‡§¶", "‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§¨‡§Ç‡§¶"]

# ---------------- LOAD VOSK ----------------
vosk_model = Model(VOSK_MODEL_PATH)
recognizer = KaldiRecognizer(vosk_model, SAMPLE_RATE)

# ---------------- MIC CALLBACK ----------------
def audio_callback(indata, frames, time, status):
    if status:
        print(status)
    q.put(bytes(indata))

# ---------------- INTENT LOGIC ----------------
def handle_intent(text):
    global awake, current_voice, music_playing
    words = text.split()

    # ---- TERMINATE ----
    if "‡§™‡•Ç‡§∞‡•Ä" in words and "‡§¨‡§Ç‡§¶" in words:
        return "__TERMINATE__"

    # ---- WAKE ----
    if not awake:
        if any(w in words for w in WAKE_WORDS):
            awake = True
            return "‡§π‡§æ‡§Å"
        return None

    # ---- SLEEP ----
    if any(w in words for w in SLEEP_WORDS):
        awake = False
        return "‡§†‡•Ä‡§ï ‡§π‡•à"

    # ---- MUSIC PLAY ----
    if ("‡§ó‡§æ‡§®‡§æ" or "‡§ó‡§æ‡§Ø‡§®") in words and not music_playing:
        return "__PLAY_SONG__"

    # ---- MUSIC STOP ----
    if "‡§¨‡§Ç‡§¶" in words and music_playing:
        return "__STOP_SONG__"

    # ---- VOICE SWITCH ----
    if "‡§≤‡§°‡§º‡§ï‡•Ä" in words or "‡§Æ‡§π‡§ø‡§≤‡§æ" in words:
        current_voice = "female"
        return "‡§Ü‡§µ‡§æ‡§ú‡§º ‡§¨‡§¶‡§≤ ‡§¶‡•Ä"

    if "‡§≤‡§°‡§º‡§ï‡§æ" in words or "‡§™‡•Å‡§∞‡•Å‡§∑" in words:
        current_voice = "male"
        return "‡§Ü‡§µ‡§æ‡§ú‡§º ‡§¨‡§¶‡§≤ ‡§¶‡•Ä"

    from datetime import datetime

    # ---- TIME / DATE ----
    if any(w in words for w in ["‡§∏‡§Æ‡§Ø", "‡§¨‡§ú‡•á", "‡§ï‡§ø‡§§‡§®‡§æ"]):
        return f"‡§Ö‡§≠‡•Ä ‡§ï‡§æ ‡§∏‡§Æ‡§Ø ‡§π‡•à {datetime.now().strftime('%H:%M')}"

    if "‡§§‡§æ‡§∞‡•Ä‡§ñ" in words:
        return f"‡§Ü‡§ú ‡§ï‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§ñ {datetime.now().strftime('%d %B %Y')} ‡§π‡•à"

    if "‡§¶‡§ø‡§®" in words and "‡§Ü‡§ú" in words:
        return f"‡§Ü‡§ú {datetime.now().strftime('%A')} ‡§π‡•à"

    if "‡§¶‡§ø‡§®" in words or "‡§∞‡§æ‡§§" in words:
        return "‡§Ö‡§≠‡•Ä ‡§¶‡§ø‡§® ‡§π‡•à" if 6 <= datetime.now().hour < 18 else "‡§Ö‡§≠‡•Ä ‡§∞‡§æ‡§§ ‡§π‡•à"

    # ---- IDENTITY ----
    if "‡§®‡§æ‡§Æ" in words:
        return "‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à"

    if "‡§ï‡•å‡§®" in words:
        return "‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§ë‡§´‡§≤‡§æ‡§á‡§® ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•Ç‡§Å"

    if "‡§¨‡§®‡§æ‡§Ø‡§æ" in words:
        return "‡§Æ‡•Å‡§ù‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à"

    # ---- SOCIAL ----
    if any(w in words for w in ["‡§®‡§Æ‡§∏‡•ç‡§§‡•á", "‡§π‡§æ‡§Ø"]):
        return "‡§®‡§Æ‡§∏‡•ç‡§§‡•á"

    if "‡§ï‡•à‡§∏‡•á" in words:
        return "‡§Æ‡•à‡§Ç ‡§†‡•Ä‡§ï ‡§π‡•Ç‡§Å"

    if "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶" in words:
        return "‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à"

    if "‡§Ö‡§≤‡§µ‡§ø‡§¶‡§æ" in words:
        return "‡§´‡§ø‡§∞ ‡§Æ‡§ø‡§≤‡•á‡§Ç‡§ó‡•á"

    return None

# ---------------- TTS ----------------
def speak(text):
    print("üîä Speaking:", text)

    output_wav = "output.wav"

    subprocess.run(
        [
            PIPER_EXE,
            "--model", VOICE_MODELS[current_voice],
            "--output_file", output_wav
        ],
        input=text.encode("utf-8"),
        check=True
    )

    winsound.PlaySound(output_wav, winsound.SND_FILENAME)

# ---------------- MAIN LOOP ----------------
def main():
    global last_text, music_playing
    print("üé§ Hindi Assistant is listening...")

    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype="int16",
        callback=audio_callback
    ):
        while True:
            data = q.get()
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                text = result.get("text", "").strip()

                if not text or text == last_text:
                    continue

                print("You said:", text)

                reply = handle_intent(text)

                if reply == "__PLAY_SONG__":
                    winsound.PlaySound(
                        SONG_PATH,
                        winsound.SND_FILENAME | winsound.SND_ASYNC
                    )
                    music_playing = True
                    last_text = text
                    continue

                if reply == "__STOP_SONG__":
                    winsound.PlaySound(None, winsound.SND_PURGE)
                    music_playing = False
                    last_text = text
                    continue

                if reply == "__TERMINATE__":
                    speak("‡§∏‡§π‡§æ‡§Ø‡§ï ‡§¨‡§Ç‡§¶ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à")
                    break

                if reply:
                    print("Assistant:", reply)
                    speak(reply)

                last_text = text

# ---------------- RUN ----------------
if __name__ == "__main__":
    main()
